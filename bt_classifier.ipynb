{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fb1bfc",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "Brief description of the brain tumor image classification project.\n",
    "\n",
    "In this section, I converted all images to RGB format and resized them to (224, 224).\n",
    "I also applied a set of transformations to normalize the data properly, which is a common preprocessing step before feeding the images into a convolutional neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: img.convert(\"RGB\")),  # Ensure RGB\n",
    "    transforms.Resize((224, 224)),                      # Resize to 224x224\n",
    "    transforms.ToTensor(),                              # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)      # Normalize to [-1,1]\n",
    "])\n",
    "\n",
    "# Step 2: Define relative paths\n",
    "base_dir = Path.cwd()\n",
    "train_dir = base_dir / \"archive\" / \"training\"\n",
    "test_dir = base_dir / \"archive\" / \"testing\"\n",
    "\n",
    "# Step 3: Load datasets with transformations\n",
    "train_dataset = datasets.ImageFolder(root=str(train_dir), transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=str(test_dir), transform=transform)\n",
    "\n",
    "# Step 4: Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Step 5: Check the detected classes\n",
    "print(\"Detected classes:\", train_dataset.classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b5ee3a-852b-4c5b-b8c2-56f42252a150",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "I verified that no class rebalancing is necessary, since the number of images per class is already reasonably balanced.\n",
    "Additionally, I displayed several examples of the images after preprocessing to visualize how they look before being passed to the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871dac93-6d34-4d63-85ec-5742170d0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = [label for _, label in train_dataset]\n",
    "counter = Counter(labels)\n",
    "\n",
    "plt.bar(counter.keys(), counter.values(), tick_label=train_dataset.classes)\n",
    "plt.title(\"Class distribution (training set)\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff6abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse normalization: from [-1,1] to [0,1]\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-1.0, -1.0, -1.0],\n",
    "    std=[2.0, 2.0, 2.0]\n",
    ")\n",
    "\n",
    "# Collect one image per class\n",
    "class_images = {}\n",
    "for img, label in train_dataset:\n",
    "    class_name = train_dataset.classes[label]\n",
    "    if class_name not in class_images:\n",
    "        class_images[class_name] = img\n",
    "    if len(class_images) == len(train_dataset.classes):\n",
    "        break\n",
    "\n",
    "# Display: row 1 -> normalized, row 2 -> de-normalized\n",
    "n_classes = len(class_images)\n",
    "plt.figure(figsize=(n_classes * 2.5, 5))\n",
    "\n",
    "for idx, (class_name, img) in enumerate(class_images.items()):\n",
    "    # Row 1: Normalized image\n",
    "    plt.subplot(2, n_classes, idx + 1)\n",
    "    plt.imshow(img.permute(1, 2, 0).numpy())\n",
    "    plt.title(f\"{class_name}\\n(normalized)\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Row 2: De-normalized image (to visualize properly)\n",
    "    img_inv = inv_normalize(img)\n",
    "    img_inv = torch.clamp(img_inv, 0, 1)  # ensure values are in [0,1]\n",
    "    plt.subplot(2, n_classes, n_classes + idx + 1)\n",
    "    plt.imshow(img_inv.permute(1, 2, 0).numpy())\n",
    "    plt.title(f\"{class_name}\\n(original)\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d4b02",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "Define the architecture of the classification model (e.g., CNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfa5a91",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "Train the model using the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc76abb9",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "Evaluate the model performance on the validation/test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9aade7",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "\n",
    "Make predictions on new or unseen images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5468929",
   "metadata": {},
   "source": [
    "# Conclusions and Next Steps\n",
    "\n",
    "Summarize findings and suggest future improvements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
